

--- Transform ---


Load Cached data, features/parse_calendar.pkl
Load Cached data, features/parse_sell_prices.pkl
Load Cached data, features/parse_sales_train.pkl
Load Cached data, features/melted_and_merged_train.pkl


--- Create Features ---


Load Cached data, features/all_data.pkl


--- Split Data ---


Split all_train_data to features/all_train_data.pkl
Split eval_data to features/eval_data.pkl
Split submit_data to features/submit_data.pkl
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 23965140 entries, 0 to 23965139
Data columns (total 103 columns):
 #   Column                       Dtype         
---  ------                       -----         
 0   id                           object        
 1   item_id                      category      
 2   dept_id                      category      
 3   cat_id                       category      
 4   store_id                     category      
 5   state_id                     category      
 6   d                            object        
 7   sales                        int16         
 8   date                         datetime64[ns]
 9   wm_yr_wk                     int16         
 10  event_name_1                 category      
 11  event_type_1                 category      
 12  event_name_2                 category      
 13  event_type_2                 category      
 14  snap_CA                      int8          
 15  snap_TX                      int8          
 16  snap_WI                      int8          
 17  year                         int16         
 18  quarter                      int8          
 19  month                        int8          
 20  week                         int8          
 21  weekofyear                   int8          
 22  day                          int8          
 23  dayofweek                    int8          
 24  dayofyear                    int16         
 25  is_month_end                 bool          
 26  is_month_start               bool          
 27  is_weekend                   bool          
 28  sell_price                   float16       
 29  price_max                    float16       
 30  price_min                    float16       
 31  price_std                    float16       
 32  price_mean                   float16       
 33  price_nunique                float16       
 34  release                      float16       
 35  id_nunique_by_price          float16       
 36  price_norm                   float16       
 37  sales_lag_t0                 float16       
 38  sales_lag_t1                 float16       
 39  sales_lag_t2                 float16       
 40  sales_lag_t3                 float16       
 41  sales_lag_t4                 float16       
 42  sales_lag_t5                 float16       
 43  sales_lag_t6                 float16       
 44  sales_lag_t7                 float16       
 45  sales_lag_t8                 float16       
 46  sales_lag_t9                 float16       
 47  sales_lag_t10                float16       
 48  sales_lag_t11                float16       
 49  sales_lag_t12                float16       
 50  sales_lag_t13                float16       
 51  sales_lag_t14                float16       
 52  sales_roll_mean_t1_7         float16       
 53  sales_roll_std_t1_7          float16       
 54  sales_roll_mean_t1_14        float16       
 55  sales_roll_std_t1_14         float16       
 56  sales_roll_mean_t1_30        float16       
 57  sales_roll_std_t1_30         float16       
 58  sales_roll_mean_t7_7         float16       
 59  sales_roll_std_t7_7          float16       
 60  sales_roll_mean_t7_14        float16       
 61  sales_roll_std_t7_14         float16       
 62  sales_roll_mean_t7_30        float16       
 63  sales_roll_std_t7_30         float16       
 64  sales_roll_mean_t14_7        float16       
 65  sales_roll_std_t14_7         float16       
 66  sales_roll_mean_t14_14       float16       
 67  sales_roll_std_t14_14        float16       
 68  sales_roll_mean_t14_30       float16       
 69  sales_roll_std_t14_30        float16       
 70  sales_rolling_ZeroRatio_t7   float16       
 71  sales_rolling_ZeroCount_t7   float16       
 72  sales_rolling_ZeroRatio_t14  float16       
 73  sales_rolling_ZeroCount_t14  float16       
 74  sales_rolling_ZeroRatio_t30  float16       
 75  sales_rolling_ZeroCount_t30  float16       
 76  sales_rolling_skew_t30       float16       
 77  sales_rolling_kurt_t30       float16       
 78  price_momentum               float16       
 79  price_momentum_m             float16       
 80  days_from_last_sales         int64         
 81  enc_state_id_mean            float16       
 82  enc_state_id_std             float16       
 83  enc_store_id_mean            float16       
 84  enc_store_id_std             float16       
 85  enc_cat_id_mean              float16       
 86  enc_cat_id_std               float16       
 87  enc_dept_id_mean             float16       
 88  enc_dept_id_std              float16       
 89  enc_state_id_cat_id_mean     float16       
 90  enc_state_id_cat_id_std      float16       
 91  enc_state_id_dept_id_mean    float16       
 92  enc_state_id_dept_id_std     float16       
 93  enc_store_id_cat_id_mean     float16       
 94  enc_store_id_cat_id_std      float16       
 95  enc_store_id_dept_id_mean    float16       
 96  enc_store_id_dept_id_std     float16       
 97  enc_item_id_mean             float16       
 98  enc_item_id_std              float16       
 99  enc_item_id_state_id_mean    float16       
 100 enc_item_id_state_id_std     float16       
 101 enc_item_id_store_id_mean    float16       
 102 enc_item_id_store_id_std     float16       
dtypes: bool(3), category(9), datetime64[ns](1), float16(74), int16(4), int64(1), int8(9), object(2)
memory usage: 4.7+ GB
None


--- Train ---


Load Cached data, features/evaluator.pkl

Parameters:
 {
    "boosting": "gbdt",
    "objective": "tweedie",
    "tweedie_variance_power": 1.1,
    "metric": "custom",
    "num_leaves": 127,
    "min_data_in_leaf": 20,
    "seed": 42,
    "learning_rate": 0.03,
    "subsample": 0.8,
    "subsample_freq": 1,
    "feature_fraction": 0.8,
    "force_row_wise": true,
    "verbose": -1
} 



Group ID: HOBBIES_1, 1/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.104925
[200]	valid_0's WRMSSE: 0.0974771
[300]	valid_0's WRMSSE: 0.0966245
[400]	valid_0's WRMSSE: 0.0966592
Early stopping, best iteration is:
[307]	valid_0's WRMSSE: 0.0966171


Group ID: HOBBIES_2, 2/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.0044814
[200]	valid_0's WRMSSE: 0.00445647
[300]	valid_0's WRMSSE: 0.00446111
Early stopping, best iteration is:
[207]	valid_0's WRMSSE: 0.00445615


Group ID: HOUSEHOLD_1, 3/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.208395
[200]	valid_0's WRMSSE: 0.197174
[300]	valid_0's WRMSSE: 0.195511
[400]	valid_0's WRMSSE: 0.19532
[500]	valid_0's WRMSSE: 0.195206
[600]	valid_0's WRMSSE: 0.195056
[700]	valid_0's WRMSSE: 0.194977
[800]	valid_0's WRMSSE: 0.194916
[900]	valid_0's WRMSSE: 0.194856
[1000]	valid_0's WRMSSE: 0.194782
[1100]	valid_0's WRMSSE: 0.194762
Early stopping, best iteration is:
[1093]	valid_0's WRMSSE: 0.194731


Group ID: HOUSEHOLD_2, 4/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.0585089
[200]	valid_0's WRMSSE: 0.0570376
[300]	valid_0's WRMSSE: 0.056809
[400]	valid_0's WRMSSE: 0.0567872
[500]	valid_0's WRMSSE: 0.0568016
Early stopping, best iteration is:
[420]	valid_0's WRMSSE: 0.0567835


Group ID: FOODS_1, 5/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.0670664
[200]	valid_0's WRMSSE: 0.0578628
[300]	valid_0's WRMSSE: 0.0562999
[400]	valid_0's WRMSSE: 0.0562574
Early stopping, best iteration is:
[334]	valid_0's WRMSSE: 0.056188


Group ID: FOODS_2, 6/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.153214
[200]	valid_0's WRMSSE: 0.142163
[300]	valid_0's WRMSSE: 0.139252
[400]	valid_0's WRMSSE: 0.138252
[500]	valid_0's WRMSSE: 0.137815
[600]	valid_0's WRMSSE: 0.137597
[700]	valid_0's WRMSSE: 0.137452
[800]	valid_0's WRMSSE: 0.137426
Early stopping, best iteration is:
[766]	valid_0's WRMSSE: 0.137411


Group ID: FOODS_3, 7/8
[LightGBM] [Info] Saving data to binary file tmp_train_set.bin
[LightGBM] [Info] Saving data to binary file tmp_valid_set.bin
Training until validation scores don't improve for 100 rounds
[100]	valid_0's WRMSSE: 0.33953
[200]	valid_0's WRMSSE: 0.295231
[300]	valid_0's WRMSSE: 0.286673
[400]	valid_0's WRMSSE: 0.284765
[500]	valid_0's WRMSSE: 0.284209
[600]	valid_0's WRMSSE: 0.284159
Early stopping, best iteration is:
[588]	valid_0's WRMSSE: 0.284059


--- Evaluation ---


Load Cached data, features/evaluator.pkl

Our val RMSE score is 2.098451793514478
Our val WRMSSE score is 0.6927958027351977


--- Submission ---


(60980, 29)
                              id        F1        F2        F3        F4  \
0  HOBBIES_1_001_CA_1_validation  0.784737  0.762226  0.752250  0.727320   
1  HOBBIES_1_002_CA_1_validation  0.373652  0.380595  0.381113  0.381113   
2  HOBBIES_1_003_CA_1_validation  0.350048  0.346172  0.346172  0.346172   
3  HOBBIES_1_004_CA_1_validation  1.997424  1.916832  1.925511  1.848776   
4  HOBBIES_1_005_CA_1_validation  1.161026  1.120570  1.184266  1.255358   

         F5        F6        F7        F8        F9       F10       F11  \
0  0.783587  0.848495  0.870595  0.696225  0.692053  0.710055  0.702168   
1  0.437408  0.466240  0.469098  0.366416  0.353285  0.337109  0.335932   
2  0.410189  0.466482  0.498741  0.344879  0.329418  0.320016  0.324991   
3  2.282130  2.540956  2.622865  1.908242  1.813051  1.842090  1.660350   
4  1.396937  1.490878  1.648889  1.350367  1.321090  1.242098  1.203096   

        F12       F13       F14       F15       F16       F17       F18  \
0  0.783752  0.908750  0.839685  0.750503  0.712233  0.710883  0.733788   
1  0.363311  0.375773  0.362661  0.269370  0.268898  0.268898  0.268898   
2  0.375280  0.431158  0.414394  0.305090  0.302322  0.310201  0.329443   
3  2.006053  2.828655  2.466445  1.726087  1.705948  1.793660  1.723192   
4  1.289099  1.502733  1.372986  1.230909  1.176615  1.226275  1.216155   

        F19       F20       F21       F22       F23       F24       F25  \
0  0.794480  0.934989  0.937458  0.748177  0.781175  0.745518  0.733194   
1  0.284767  0.309732  0.308994  0.265011  0.264602  0.297307  0.296748   
2  0.407735  0.530713  0.534996  0.423157  0.433459  0.442486  0.445700   
3  2.101225  2.397857  2.795605  1.907615  1.828661  1.684024  1.683379   
4  1.265499  1.495250  1.537493  1.115075  1.087443  1.057394  1.108383   

        F26       F27       F28  
0  0.778926  0.928546  0.927282  
1  0.328748  0.361539  0.351544  
2  0.527973  0.599328  0.604035  
3  2.141535  2.916348  2.701135  
4  1.261221  1.555052  1.600397  
