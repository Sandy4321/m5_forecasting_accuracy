{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v02000 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Baseline を見直す\n",
    "    - 予測変数を対数変換しない。\n",
    "    - モデルを poission から regression に変更する\n",
    "- [x] WRMSSE の評価関数クラスを定義し、評価を行う。\n",
    "- [x] Competition Evaluation と Training Evaluation を用意したい。\n",
    "    - 学習では柔軟度が高く、使いやすい関数を良いしたい。\n",
    "    - 評価では、できるだけLBと近い値で評価したい。\n",
    "- [x] WRMSSE の評価関数クラスを定義し、LightGBM の評価関数として使う\n",
    "- [x] 損失関数にRMSLEを適応してみる。\n",
    "    - `lr=0.1` では学習率が大きすぎた。（対数変換をした評価が見られていないのでスコアが上昇するのか未確認）\n",
    "- [x] poisson 回帰を試す。\n",
    "    - Local CV 0.55645 -> 0.52480 に変化した。\n",
    "- [ ] 特徴量の追加\n",
    "    -  https://www.kaggle.com/rohitsingh9990/m5-lgbm-fe?scriptVersionId=30700291\n",
    "    - コスト関数を変えれば`0.55690`まで上がるらしい。\n",
    "    - 特徴量のcacheは、どの特徴量がどのような影響があるのかを実験するために、役割ごとで分けて作ったほうがよさそう。\n",
    "- [ ] Group K fold で学習してみる。\n",
    "    - https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv\n",
    "- [ ] Cut off lags nan rows\n",
    "- [ ] カテゴリごとの標準化でスコアが改善するか試す\n",
    "- [ ] 特徴量の追加、Aggregated Sales Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VERSION = 'v02002'\n",
    "TARGET = 'sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# custom funcs\n",
    "from script import WRMSSEEvaluator\n",
    "from script import cache_result\n",
    "from script import reduce_mem_usage\n",
    "from script import load_pickle, dump_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data And Initial Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache to features/parse_calendar.pkl\n"
     ]
    }
   ],
   "source": [
    "@cache_result(filename='parse_calendar', use_cache=False)\n",
    "def parse_calendar():\n",
    "    calendar = pd.read_pickle('../data/reduced/calendar.pkl')\n",
    "    # fill null feature\n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for f in nan_features:\n",
    "        calendar[f].fillna('null', inplace=True)\n",
    "    # label encoding\n",
    "    cat_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for f in cat_features:\n",
    "        encodaer = preprocessing.LabelEncoder()\n",
    "        calendar[f] = encodaer.fit_transform(calendar[f])\n",
    "        \n",
    "    calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "    attrs = [\n",
    "        \"year\",\n",
    "#         \"quarter\",\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "#         \"weekofyear\",\n",
    "        \"day\",\n",
    "        \"dayofweek\",\n",
    "#         \"is_year_end\",\n",
    "#         \"is_year_start\",\n",
    "#         \"is_quarter_end\",\n",
    "#         \"is_quarter_start\",\n",
    "#         \"is_month_end\",\n",
    "#         \"is_month_start\",\n",
    "    ]\n",
    "\n",
    "    for attr in attrs:\n",
    "        calendar[attr] = getattr(calendar['date'].dt, attr)\n",
    "#     calendar[\"is_weekend\"] = calendar[\"dayofweek\"].isin([5, 6]).astype(np.int8)|\n",
    "        \n",
    "#     drop_features = ['weekday', 'wday', 'month', 'year']\n",
    "#     features = calendar.columns.tolist()\n",
    "#     features = [f for f in features if f not in drop_features]\n",
    "    return calendar\n",
    " \n",
    "\n",
    "_ = parse_calendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_result(filename='parse_sell_prices', use_cache=True)\n",
    "def parse_sell_prices():\n",
    "    sell_prices = pd.read_pickle('../data/reduced/sell_prices.pkl')\n",
    "    return sell_prices\n",
    "\n",
    "_ = parse_sell_prices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_result(filename='parse_sales_train', use_cache=True)\n",
    "def parse_sales_train():\n",
    "    train = pd.read_pickle('../data/reduced/sales_train_validation.pkl')\n",
    "    # Add Prediction Columns\n",
    "    start_d = 1914\n",
    "    end_d = 1969\n",
    "    for i in range(start_d, end_d+1):\n",
    "        train[f'd_{i}'] = 0\n",
    "    return train\n",
    "\n",
    "_ = parse_sales_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_result(filename='melted_and_merged_train', use_cache=True)\n",
    "def melted_and_merged_train():\n",
    "    # Load Data\n",
    "    calendar = pd.read_pickle('features/parse_calendar.pkl')\n",
    "    sell_prices = pd.read_pickle('features/parse_sell_prices.pkl')\n",
    "    df = pd.read_pickle('features/parse_sales_train.pkl')\n",
    "    \n",
    "    idx_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    df = pd.melt(df, id_vars=idx_cols, var_name='d', value_name='sales')\n",
    "    df = pd.merge(df, calendar, how='left', on='d')\n",
    "    df = pd.merge(df, sell_prices, how='left', on=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "    \n",
    "    # Label Encoding\n",
    "    cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    for c in cat_cols:\n",
    "        encodaer = preprocessing.LabelEncoder()\n",
    "        df[c] = encodaer.fit_transform(df[c])\n",
    "        \n",
    "    df.dropna(subset=['sell_price'], axis=0, inplace=True)\n",
    "    return df.pipe(reduce_mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_result(filename='simple_fe', use_cache=True)\n",
    "def simple_fe():\n",
    "    df = pd.read_pickle('features/melted_and_merged_train.pkl')\n",
    "    # rolling demand features\n",
    "    df['sales_lag_t28'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28))\n",
    "    df['sales_lag_t29'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(29))\n",
    "    df['sales_lag_t30'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(30))\n",
    "    df['sales_rolling_mean_t7'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    df['sales_rolling_std_t7'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "    df['sales_rolling_mean_t30'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(30).mean())\n",
    "    df['sales_rolling_mean_t90'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(90).mean())\n",
    "    df['sales_rolling_mean_t180'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(180).mean())\n",
    "    df['sales_rolling_std_t30'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(30).std())\n",
    "    df['sales_rolling_skew_t30'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(30).skew())\n",
    "    df['sales_rolling_kurt_t30'] = df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(30).kurt())\n",
    "    \n",
    "    # price features\n",
    "    df['price_lag_t1'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1)) # after drop.\n",
    "    df['price_change_t1'] = (df['price_lag_t1'] - df['sell_price']) / (df['price_lag_t1'])\n",
    "    df['rolling_price_max_t365'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max()) # after drop.\n",
    "    df['price_change_t365'] = (df['rolling_price_max_t365'] - df['sell_price']) / (df['rolling_price_max_t365'])\n",
    "    df['price_rolling_std_t7'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(7).std())\n",
    "    df['price_rolling_std_t30'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(30).std())\n",
    "    df.drop(['rolling_price_max_t365', 'price_lag_t1'], inplace = True, axis = 1)\n",
    "    \n",
    "    return df.pipe(reduce_mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = simple_fe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47735397, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sales_lag_t28</th>\n",
       "      <th>sales_lag_t29</th>\n",
       "      <th>sales_lag_t30</th>\n",
       "      <th>sales_rolling_mean_t7</th>\n",
       "      <th>sales_rolling_std_t7</th>\n",
       "      <th>sales_rolling_mean_t30</th>\n",
       "      <th>sales_rolling_mean_t90</th>\n",
       "      <th>sales_rolling_mean_t180</th>\n",
       "      <th>sales_rolling_std_t30</th>\n",
       "      <th>sales_rolling_skew_t30</th>\n",
       "      <th>sales_rolling_kurt_t30</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>price_rolling_std_t7</th>\n",
       "      <th>price_rolling_std_t30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>1444</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>1445</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>1446</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>1448</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>1451</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  item_id  dept_id  cat_id  store_id  \\\n",
       "7   HOBBIES_1_008_CA_1_validation     1444        3       1         0   \n",
       "8   HOBBIES_1_009_CA_1_validation     1445        3       1         0   \n",
       "9   HOBBIES_1_010_CA_1_validation     1446        3       1         0   \n",
       "11  HOBBIES_1_012_CA_1_validation     1448        3       1         0   \n",
       "14  HOBBIES_1_015_CA_1_validation     1451        3       1         0   \n",
       "\n",
       "    state_id    d  sales       date  wm_yr_wk   weekday  wday  month  year  \\\n",
       "7          0  d_1     12 2011-01-29     11101  Saturday     1      1  2011   \n",
       "8          0  d_1      2 2011-01-29     11101  Saturday     1      1  2011   \n",
       "9          0  d_1      0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "11         0  d_1      0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "14         0  d_1      4 2011-01-29     11101  Saturday     1      1  2011   \n",
       "\n",
       "    event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n",
       "7             30             4             4             2        0        0   \n",
       "8             30             4             4             2        0        0   \n",
       "9             30             4             4             2        0        0   \n",
       "11            30             4             4             2        0        0   \n",
       "14            30             4             4             2        0        0   \n",
       "\n",
       "    snap_WI  week  day  dayofweek  sell_price  sales_lag_t28  sales_lag_t29  \\\n",
       "7         0     4   29          5    0.459961            NaN            NaN   \n",
       "8         0     4   29          5    1.559570            NaN            NaN   \n",
       "9         0     4   29          5    3.169922            NaN            NaN   \n",
       "11        0     4   29          5    5.980469            NaN            NaN   \n",
       "14        0     4   29          5    0.700195            NaN            NaN   \n",
       "\n",
       "    sales_lag_t30  sales_rolling_mean_t7  sales_rolling_std_t7  \\\n",
       "7             NaN                    NaN                   NaN   \n",
       "8             NaN                    NaN                   NaN   \n",
       "9             NaN                    NaN                   NaN   \n",
       "11            NaN                    NaN                   NaN   \n",
       "14            NaN                    NaN                   NaN   \n",
       "\n",
       "    sales_rolling_mean_t30  sales_rolling_mean_t90  sales_rolling_mean_t180  \\\n",
       "7                      NaN                     NaN                      NaN   \n",
       "8                      NaN                     NaN                      NaN   \n",
       "9                      NaN                     NaN                      NaN   \n",
       "11                     NaN                     NaN                      NaN   \n",
       "14                     NaN                     NaN                      NaN   \n",
       "\n",
       "    sales_rolling_std_t30  sales_rolling_skew_t30  sales_rolling_kurt_t30  \\\n",
       "7                     NaN                     NaN                     NaN   \n",
       "8                     NaN                     NaN                     NaN   \n",
       "9                     NaN                     NaN                     NaN   \n",
       "11                    NaN                     NaN                     NaN   \n",
       "14                    NaN                     NaN                     NaN   \n",
       "\n",
       "    price_change_t1  price_change_t365  price_rolling_std_t7  \\\n",
       "7               NaN                NaN                   NaN   \n",
       "8               NaN                NaN                   NaN   \n",
       "9               NaN                NaN                   NaN   \n",
       "11              NaN                NaN                   NaN   \n",
       "14              NaN                NaN                   NaN   \n",
       "\n",
       "    price_rolling_std_t30  \n",
       "7                     NaN  \n",
       "8                     NaN  \n",
       "9                     NaN  \n",
       "11                    NaN  \n",
       "14                    NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42840/42840 [00:05<00:00, 8020.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache to features/evaluator.pkl\n"
     ]
    }
   ],
   "source": [
    "''' Note.\n",
    "- この関数の制約は\n",
    "    - validation では, すべての id が存在し, 連続する28日のデータであること.\n",
    "    - validation と prediction の id の順序が同一であること.\n",
    "'''\n",
    "class WRMSSEForLightGBM(WRMSSEEvaluator):\n",
    "    def feval(self, preds, dtrain):\n",
    "        row, col = self.valid_df[self.valid_target_columns].shape\n",
    "        preds = preds.reshape(col, row).T\n",
    "        \n",
    "        score = self.score(preds)\n",
    "        return 'WRMSSE', score, False\n",
    "    \n",
    "    def get_sample_weight(self, data_idx):\n",
    "        '''\n",
    "        sample weight for rmse.\n",
    "        Weights for doing WRMSSE-like evaluations using RMSE.\n",
    "        '''\n",
    "        data_idx = data_idx.apply(lambda x: x.rsplit('_', 1)[0]).values\n",
    "        \n",
    "        weight_df = self.weights * 12\n",
    "        weight_df.index = weight_df.index.str.replace('--', '_')\n",
    "        weight_df.columns = ['weight']\n",
    "        scale = np.where(self.scale != 0, self.scale, 1)\n",
    "        weight_df['sample_weight'] = weight_df['weight'] / scale\n",
    "\n",
    "        return weight_df.loc[data_idx, 'sample_weight'].values\n",
    "\n",
    "\n",
    "    \n",
    "@cache_result(filename='evaluator', use_cache=False)\n",
    "def get_evaluator():\n",
    "    train_df = pd.read_pickle('../data/reduced/sales_train_validation.pkl')\n",
    "\n",
    "    train_fold_df = train_df.iloc[:, :-28]\n",
    "    valid_fold_df = train_df.iloc[:, -28:].copy()\n",
    "\n",
    "    evaluator = WRMSSEForLightGBM(\n",
    "        train_df=train_fold_df, \n",
    "        valid_df=valid_fold_df, \n",
    "        calendar=pd.read_pickle('../data/reduced/calendar.pkl'), \n",
    "        prices=pd.read_pickle('../data/reduced/sell_prices.pkl')\n",
    "    )\n",
    "    \n",
    "    return evaluator\n",
    "    \n",
    "evaluator = get_evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split Data '''\n",
    "def train_eval_submit_split(df, eval_days=28):\n",
    "    submit_mask = (df[\"date\"] >= '2016-04-25')\n",
    "\n",
    "    eval_date = datetime.datetime.strptime('2016-04-25', '%Y-%m-%d') - datetime.timedelta(days=eval_days)\n",
    "    eval_mask = ((df[\"date\"] >= eval_date) & (df[\"date\"] < '2016-04-25'))\n",
    "    \n",
    "    train_mask = ((~eval_mask) & (~submit_mask))\n",
    "    return df[train_mask], df[eval_mask], df[submit_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data, eval_data, sub_data = train_eval_submit_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sales'\n",
    "features = [\n",
    "    'item_id',\n",
    "    'dept_id',\n",
    "    'cat_id',\n",
    "    'store_id',\n",
    "    'state_id',\n",
    "    'day',\n",
    "    'event_name_1',\n",
    "    'event_type_1',\n",
    "    'event_name_2',\n",
    "    'event_type_2',\n",
    "    'snap_CA',\n",
    "    'snap_TX',\n",
    "    'snap_WI',\n",
    "    'sell_price',\n",
    "    'sales_lag_t28',\n",
    "    'sales_lag_t29',\n",
    "    'sales_lag_t30',\n",
    "    'sales_rolling_mean_t7',\n",
    "    'sales_rolling_std_t7',\n",
    "    'sales_rolling_mean_t30',\n",
    "    'sales_rolling_mean_t90',\n",
    "    'sales_rolling_mean_t180',\n",
    "    'sales_rolling_std_t30',\n",
    "    'sales_rolling_skew_t30',\n",
    "    'sales_rolling_kurt_t30',\n",
    "    'price_change_t1',\n",
    "    'price_change_t365',\n",
    "    'price_rolling_std_t7',\n",
    "    'price_rolling_std_t30',\n",
    "    'year',\n",
    "    'month',\n",
    "    'week',\n",
    "    'dayofweek'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(all_train_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(train_data[features], train_data[target])\n",
    "val_set = lgb.Dataset(valid_data[features], valid_data[target], reference=train_set)\n",
    "\n",
    "use_weight = True\n",
    "if use_weight:\n",
    "    train_set.set_weight(evaluator.get_sample_weight(train_data['id']))\n",
    "    val_set.set_weight(evaluator.get_sample_weight(valid_data['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(preds, actual, weight=None):\n",
    "    return mean_squared_error(np.log1p(actual), np.log1p(preds), sample_weight=weight, squared=False)\n",
    "\n",
    "\n",
    "def lgbm_rmsle(preds, data):\n",
    "    weight = data.get_weight()\n",
    "    metric_name = 'RMSLE' if weight is None else 'WRMSLE'\n",
    "    return metric_name, rmsle(preds, data.get_label(), weight), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'poisson',\n",
    "    'learning_rate': 0.3,\n",
    "    'num_leaves': 2**7-1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': SEED\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'num_boost_round': 2500, \n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose_eval': 100,\n",
    "#     'feval': lgbm_rmsle\n",
    "#     'feval': evaluator.feval\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 48.9515\ttraining's WRMSLE: 0.430698\tvalid_1's rmse: 48.2453\tvalid_1's WRMSLE: 0.431399\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-2995652a8f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repositories/m5_forecasting_accuracy/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositories/m5_forecasting_accuracy/.venv/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \"\"\"\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositories/m5_forecasting_accuracy/.venv/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m             \u001b[0mfeval_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-9b7a5b7625fc>\u001b[0m in \u001b[0;36mlgbm_rmsle\u001b[0;34m(preds, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'RMSLE'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'WRMSLE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-9b7a5b7625fc>\u001b[0m in \u001b[0;36mrmsle\u001b[0;34m(preds, actual, weight)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     return mean_squared_error(\n\u001b[0;32m----> 3\u001b[0;31m         np.log1p(actual), np.log1p(preds), sample_weight=weight, squared=False)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, train_set, valid_sets=[train_set, val_set], **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, max_num_features=None, figsize=(10, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(eval_data[features])\n",
    "val_rmse = metrics.mean_squared_error(val_pred, eval_data[target], squared=False)\n",
    "print(f'Our val RMSE score is {val_rmse}')\n",
    "\n",
    "valid_preds = val_pred.reshape(28, -1).T\n",
    "valid_wrmsse = evaluator.score(valid_preds)\n",
    "print(f'Our val WRMSSE score is {valid_wrmsse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pred = model.predict(sub_data[features])\n",
    "\n",
    "submission = sub_data[['id', 'd']].copy(deep=True)\n",
    "submission['sales'] = sub_pred\n",
    "submission = pd.pivot(submission, index='id', columns='d', values='sales').reset_index()\n",
    "# split valid and eval\n",
    "valid_sub = submission[['id']+[f'd_{i}' for i in range(1914, 1942)]]\n",
    "eval_sub = submission[['id']+[f'd_{i}' for i in range(1942, 1970)]]\n",
    "# rename columns\n",
    "valid_sub.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "eval_sub.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "# rename id evaluation\n",
    "eval_sub = eval_sub.assign(id=lambda x: x['id'].str.replace('validation', 'evaluation'))\n",
    "\n",
    "submission = pd.concat([valid_sub, eval_sub], axis=0)\n",
    "\n",
    "sample_submission = pd.read_pickle('../data/reduced/sample_submission.pkl')\n",
    "submission = sample_submission[['id']].merge(submission, how='left', on='id')\n",
    "submission.to_csv(f'submit/{VERSION}_{valid_wrmsse:.05}.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
