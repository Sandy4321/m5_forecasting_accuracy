{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","import lightgbm as lgb\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["lgb.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'2.3.2'"},"metadata":{},"execution_count":2}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")"],"execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["data = pd.concat([train, test], sort=False)"],"execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["data['Sex'].replace(['male','female'], [0, 1], inplace=True)\n","\n","data['Embarked'].fillna(('S'), inplace=True)\n","data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n","\n","data['Fare'].fillna(np.mean(data['Fare']), inplace=True)\n","\n","age_avg = data['Age'].mean()\n","age_std = data['Age'].std()\n","\n","data['Age'].fillna(np.random.randint(age_avg - age_std, age_avg + age_std), inplace=True)\n","\n","delete_columns = ['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin']\n","data.drop(delete_columns, axis=1, inplace=True)"],"execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train = data[:len(train)]\n","test = data[len(train):]\n"],"execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["y_train = train['Survived']\n","X_train = train.drop('Survived', axis = 1)\n","X_test = test.drop('Survived', axis = 1)\n"],"execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)"],"execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["categorical_features = ['Embarked', 'Pclass', 'Sex']"],"execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n","lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n","\n","params = {\n","    'objective': 'binary'\n","}\n","\n","model = lgb.train(\n","    params, lgb_train,\n","    valid_sets=[lgb_train, lgb_eval],\n","    verbose_eval=10,\n","    num_boost_round=1000,\n","    early_stopping_rounds=10\n",")\n","\n","y_pred = model.predict(X_test, num_iteration=model.best_iteration)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Training until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.426569\tvalid_1's binary_logloss: 0.474937\n[20]\ttraining's binary_logloss: 0.355246\tvalid_1's binary_logloss: 0.450215\n[30]\ttraining's binary_logloss: 0.309672\tvalid_1's binary_logloss: 0.447568\n[40]\ttraining's binary_logloss: 0.272486\tvalid_1's binary_logloss: 0.453176\nEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.309672\tvalid_1's binary_logloss: 0.447568\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["import gc\n","import lightgbm\n","\n","\n","class LGBM_Model():\n","\n","    def __init__(\n","        self, params, train_param, train_data, valid_data,\n","        target_col, feature_cols, categorical_cols=None, train_weight=None, valid_weight=None\n","    ):\n","        self.target_col = target_col\n","        self.feature_cols = feature_cols\n","        self.categorical_cols = categorical_cols\n","               \n","        model = self.fit(params, train_param, train_data, valid_data)\n","    \n","    def _remove_bin_file(self, filepath):\n","        if os.path.exists(filepath):\n","            os.remove(filepath)\n","\n","    def _convert_dataset(self, train_data, valid_data, save_binary=True):\n","        train_dataset = lgb.Dataset(\n","            train_data[self.feature_cols], train_data[self.target_col],\n","            feature_name=self.feature_cols, categorical_feature=self.categorical_cols\n","        )\n","        valid_dataset = lgb.Dataset(\n","            valid_data[self.feature_cols], valid_data[self.target_col], reference=train_dataset\n","        )\n","        \n","        if save_binary:\n","            # Define cache filepath.\n","            train_bin_path = 'tmp_train_set.bin'\n","            valid_bin_path = 'tmp_valid_set.bin'\n","            # Remove Cached File.\n","            self._remove_bin_file(train_bin_path)\n","            self._remove_bin_file(valid_bin_path)\n","            # Save Binary Cache.\n","            train_dataset.save_binary(train_bin_path)\n","            valid_dataset.save_binary(valid_bin_path)\n","            # Reload Binary Cache.\n","            train_dataset = lgb.Dataset(train_bin_path)\n","            valid_dataset = lgb.Dataset(valid_bin_path)\n","\n","        return train_dataset, valid_dataset\n","\n","    def fit(self, params, train_param, train_data, valid_data):\n","        train_dataset, valid_dataset = self._convert_dataset(train_data, valid_data)\n","        \n","        self.model = lgb.train(\n","            params, train_dataset, \n","            valid_sets=[train_dataset, valid_dataset],\n","            **train_param\n","        )\n","\n","    def predict(self, data):\n","        return self.model.predict(data, num_iteration=model.best_iteration)\n","           \n","\n","    def get_importance(self):\n","        # Define Feature Importance DataFrame.\n","        imp_df = pd.DataFrame(\n","            [self.model.feature_importance()],\n","            columns=self.model.feature_name(),\n","            index=['Importance']\n","        ).T\n","        imp_df.sort_values(by='Importance', inplace=True)\n","        return imp_df\n","\n","    def save_importance(self, filepath, max_num_features=50, figsize=(10, 8)):\n","        imp_df = self.get_importance()\n","        # Plot Importance DataFrame.\n","        plt.figure(figsize=figsize)\n","        imp_df[-max_num_features:].plot(\n","            kind='barh', title='Feature importance', figsize=figsize,\n","            y='Importance', align=\"center\"\n","        )\n","        plt.savefig(filepath)\n","        plt.close('all')\n","\n","    \n","params = {\n","    'objective': 'binary'\n","}\n","train_param = {\n","    'verbose_eval': 10,\n","    'num_boost_round': 100,\n","    'early_stopping_rounds': 10,\n","    # 'fobj': custom_fobj,\n","    # 'feval': custom_feval\n","}\n","target = 'Survived'\n","drop_cols = ['Survived']\n","features = [f for f in train.columns.tolist() if f not in drop_cols]\n","categoricals = ['Embarked', 'Pclass', 'Sex']\n","\n","from sklearn.model_selection import train_test_split\n","train_data, valid_data  = train_test_split(train, test_size=0.3, random_state=42)\n","\n","lgb_model = LGBM_Model(params, train_param, train_data, valid_data, target, features, categoricals)\n","\n","from sklearn.metrics import roc_auc_score\n","\n","pred = lgb_model.predict(valid_data[features])\n","\n","print('\\nAUC:', roc_auc_score(valid_data[target], pred))"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":"Training until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.424818\tvalid_1's binary_logloss: 0.467657\n[20]\ttraining's binary_logloss: 0.352678\tvalid_1's binary_logloss: 0.438348\n[30]\ttraining's binary_logloss: 0.311784\tvalid_1's binary_logloss: 0.44407\nEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.352678\tvalid_1's binary_logloss: 0.438348\n\nAUC: 0.8729270671945831\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["lgb_model.save_importance(filepath='test.png')"],"execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["lgb_model.predict(X_test[features])"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([0.10245555, 0.50346386, 0.16143407, 0.08835708, 0.3464338 ,\n       0.16390117, 0.67245277, 0.22910887, 0.67569778, 0.09699357,\n       0.07134228, 0.19136593, 0.89431227, 0.09346822, 0.90750857,\n       0.8455184 , 0.17096313, 0.21431275, 0.36463652, 0.67245277,\n       0.53808075, 0.29322006, 0.90352428, 0.4591375 , 0.84022806,\n       0.05898227, 0.90306643, 0.21431275, 0.37593787, 0.27431665,\n       0.09297708, 0.10652605, 0.51163464, 0.19935972, 0.49745931,\n       0.19919661, 0.29795146, 0.29275027, 0.08740561, 0.33949013,\n       0.17196534, 0.31840153, 0.104167  , 0.91795549, 0.90750857,\n       0.13383814, 0.39512116, 0.19238485, 0.90750857, 0.60527686,\n       0.18417261, 0.28129866, 0.85767095, 0.86173787, 0.28129866,\n       0.21327232, 0.07607485, 0.15927382, 0.0853102 , 0.86173787,\n       0.10487709, 0.23713838, 0.15208164, 0.67569778, 0.40420014,\n       0.8455184 , 0.58842114, 0.1597121 , 0.36216734, 0.84022806,\n       0.69425922, 0.0674152 , 0.34161526, 0.36216734, 0.86173787,\n       0.51021432, 0.12084912, 0.84803165, 0.1541108 , 0.69425922,\n       0.63574362, 0.21336856, 0.19136593, 0.07134228, 0.13508289,\n       0.28129866, 0.60908793, 0.29275027, 0.69425922, 0.68195439,\n       0.3464338 , 0.21988775, 0.90296544, 0.12084912, 0.28158185,\n       0.30805721, 0.90750857, 0.26489522, 0.42874927, 0.1709374 ,\n       0.92057843, 0.10346981, 0.19238485, 0.30805721, 0.58162138,\n       0.07238197, 0.09076689, 0.19238485, 0.09606421, 0.15451158,\n       0.16151226, 0.60908793, 0.91718709, 0.67569778, 0.84022806,\n       0.28129866, 0.21431275, 0.65918042, 0.53625757, 0.86853337,\n       0.91075698, 0.19238485, 0.92070949, 0.12980296, 0.19238485,\n       0.6276768 , 0.19505944, 0.56304161, 0.20901774, 0.12084912,\n       0.28234669, 0.38492051, 0.19935972, 0.21431275, 0.0811488 ,\n       0.09658709, 0.22174554, 0.13653933, 0.29275027, 0.09214866,\n       0.22357616, 0.86173787, 0.48211745, 0.08023143, 0.41271472,\n       0.16703421, 0.12138121, 0.12084912, 0.31840153, 0.13466914,\n       0.89431227, 0.21160937, 0.08233654, 0.35467889, 0.13073729,\n       0.10590601, 0.86173787, 0.42874927, 0.41271472, 0.35211392,\n       0.69425922, 0.37336697, 0.90262247, 0.11691058, 0.20901774,\n       0.19935972, 0.29569257, 0.09574982, 0.8455184 , 0.29275027,\n       0.10590601, 0.22174554, 0.07956095, 0.19919661, 0.0974271 ,\n       0.91159083, 0.91159083, 0.53808075, 0.91718709, 0.90750857,\n       0.1541108 , 0.49283005, 0.91159083, 0.19238485, 0.81533389,\n       0.1153867 , 0.85767095, 0.20660025, 0.19935972, 0.20901774,\n       0.1012233 , 0.17130734, 0.15159481, 0.17264874, 0.29305151,\n       0.09780701, 0.66733788, 0.42874927, 0.13108091, 0.29795146,\n       0.72560192, 0.68195439, 0.49283005, 0.85767095, 0.12426683,\n       0.28158185, 0.67245277, 0.13108091, 0.86853337, 0.10821083,\n       0.16224806, 0.11691058, 0.18152463, 0.84803165, 0.41028868,\n       0.18832358, 0.60908793, 0.21336856, 0.84022806, 0.12084912,\n       0.91795549, 0.12975029, 0.91075698, 0.19505944, 0.84803165,\n       0.56906674, 0.19505944, 0.69425922, 0.07136454, 0.19766858,\n       0.18910445, 0.85767095, 0.10218671, 0.07701023, 0.53625757,\n       0.13047839, 0.52557923, 0.21431275, 0.91075698, 0.90750857,\n       0.84803165, 0.9034291 , 0.49283005, 0.07134228, 0.09455766,\n       0.19770963, 0.85767095, 0.10175316, 0.86853337, 0.46216546,\n       0.85767095, 0.21344744, 0.44168111, 0.09606421, 0.09654907,\n       0.10590601, 0.19238485, 0.09765749, 0.91075698, 0.19505944,\n       0.07798541, 0.08417879, 0.86853337, 0.48309307, 0.28139496,\n       0.07134228, 0.17734731, 0.10590601, 0.29795146, 0.12798847,\n       0.53625757, 0.19238485, 0.81533389, 0.72560192, 0.21431275,\n       0.85767095, 0.09622751, 0.1077789 , 0.13167465, 0.13108091,\n       0.29275027, 0.68195439, 0.69425922, 0.65626431, 0.56922493,\n       0.06421477, 0.10590601, 0.15283861, 0.19919661, 0.12084912,\n       0.11509891, 0.67245277, 0.19919661, 0.21239501, 0.09654907,\n       0.10821083, 0.91159083, 0.27431665, 0.13406198, 0.27453259,\n       0.34488612, 0.28129866, 0.11188167, 0.09709991, 0.69425922,\n       0.84803165, 0.17677733, 0.68195439, 0.21336856, 0.35467889,\n       0.11874695, 0.21431275, 0.10590601, 0.67245277, 0.84022806,\n       0.6824155 , 0.48211745, 0.182075  , 0.1704606 , 0.10652605,\n       0.30805721, 0.20624276, 0.13653933, 0.37921347, 0.86173787,\n       0.10218671, 0.91159083, 0.49283005, 0.13466914, 0.14813174,\n       0.9034291 , 0.39512116, 0.21431275, 0.70814339, 0.12865732,\n       0.18197471, 0.26597517, 0.08605845, 0.13670034, 0.19919661,\n       0.14672703, 0.24994318, 0.18776405, 0.84022806, 0.07322049,\n       0.56093678, 0.13653933, 0.67245277, 0.10566075, 0.86853337,\n       0.90750857, 0.12426683, 0.18152463, 0.24538926, 0.56922493,\n       0.19136593, 0.90750857, 0.07134228, 0.19238485, 0.60527686,\n       0.18910445, 0.90352428, 0.86853337, 0.08835708, 0.89948985,\n       0.19935972, 0.28129866, 0.19540057, 0.90750857, 0.28139496,\n       0.14061516, 0.86173787, 0.15760747, 0.20901774, 0.90750857,\n       0.84022806, 0.29275027, 0.14061516, 0.15479982, 0.6151304 ,\n       0.19238485, 0.10074579, 0.35211392, 0.61994095, 0.13816977,\n       0.89431227, 0.21988775, 0.16925734, 0.16998532, 0.6736955 ,\n       0.15283861, 0.90750857, 0.16924333, 0.17268448, 0.12220136,\n       0.90306643, 0.10541082, 0.90750857, 0.19505944, 0.23326508,\n       0.86173787, 0.10510592, 0.90306643, 0.10657165, 0.39512116,\n       0.31360445, 0.13108091, 0.48211745, 0.69425922, 0.48309307,\n       0.69425922, 0.92081417, 0.41028868, 0.12084912, 0.92081417,\n       0.06421477, 0.12084912, 0.27431665])"},"metadata":{},"execution_count":15}]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.2-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}