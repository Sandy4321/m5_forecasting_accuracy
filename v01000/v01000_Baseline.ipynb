{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Baselineを作る。\n",
    "- 簡単な特徴量エンジニアリングを行う。\n",
    "- バリデーション戦略について考える。\n",
    "- 予測精度の評価方法を決める。\n",
    "\n",
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading calendar ....\n",
      "Reading sample_submission ....\n",
      "Reading sales_train_validation ....\n",
      "Reading sell_prices ....\n"
     ]
    }
   ],
   "source": [
    "# MEMO: \n",
    "# - コンペ終了1ヶ月前には sales_train_evaluation.csv が追加される。\n",
    "# - train = sales_train_validation, test = sales_train_evaluation.\n",
    "def read_data():\n",
    "    files = ['calendar', 'sample_submission', 'sales_train_validation', 'sell_prices']\n",
    "    \n",
    "    if os.path.exists('/kaggle/input/m5-forecasting-accuracy'):\n",
    "        data_dir_path = '/kaggle/input/m5-forecasting-accuracy'\n",
    "        dst_data = {}\n",
    "        for file in files:\n",
    "            print(f'Reading {file} ....')\n",
    "            dst_data[file] = pd.read_csv(data_dir_path + file + '.csv')\n",
    "    else:\n",
    "        data_dir_path = '../data/reduced/'\n",
    "        dst_data = {}\n",
    "        for file in files:\n",
    "            print(f'Reading {file} ....')\n",
    "            dst_data[file] = pd.read_pickle(data_dir_path + file + '.pkl')\n",
    "    return dst_data.values()\n",
    "\n",
    "# TODO: sales_train_evaluation.csv が公開されたらtestに代入する。\n",
    "calendar, submission, train, sell_prices = read_data()\n",
    "test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMO: 前処理と加工を行ったデータをキャッシュとして出力しておく。\n",
    "def encode_categorical(df, cols):\n",
    "    for col in cols:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].values)\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_calendar(src_df):\n",
    "    df = src_df.copy()\n",
    "    drop_calendar_cols = ['date', 'weekday', 'year']\n",
    "    df.drop(drop_calendar_cols, axis=1, inplace=True)\n",
    "    # MEMO: N_Unique of event_name_1 == 31 and event_name_2 == 5.\n",
    "    event_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    df[event_cols] = df[event_cols].fillna('None')\n",
    "    df = encode_categorical(df, event_cols)\n",
    "    df[event_cols] = df[event_cols].astype('int8')\n",
    "    return df\n",
    "\n",
    "\n",
    "def melt_and_merge(train, test, calendar, sell_prices, use_cache=True):\n",
    "    dir_path = 'processed'\n",
    "    train_save_path = os.path.join(dir_path, 'train.pkl')\n",
    "    test_save_path = os.path.join(dir_path, 'test.pkl')\n",
    "    \n",
    "    # If se cache\n",
    "    if use_cache:\n",
    "        if os.path.exists(train_save_path) and os.path.exists(test_save_path):\n",
    "            train = pd.read_pickle(train_save_path)\n",
    "            test = pd.read_pickle(test_save_path)\n",
    "            return train, test\n",
    "           \n",
    "    # Encode Calender\n",
    "    encoded_calender = encode_calendar(calendar)\n",
    "    \n",
    "    # Encode Train Data\n",
    "    all_label_map = {}\n",
    "    label_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    id_columns = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] # Use for melt.\n",
    "    # MEMO: ラベルは全データ共通なので、train/test/sell_prices のmappingに使える。\n",
    "    for col in label_cols:\n",
    "        all_labels = sorted(train[col].unique())\n",
    "        all_label_map[col] = {label: i for i, label in enumerate(all_labels)}\n",
    "    \n",
    "    for col in label_cols:\n",
    "        # TODO: Testデータが手に入ったら mapping する。\n",
    "        train[col] = train[col].map(all_label_map[col])\n",
    "        \n",
    "        if col in ['store_id', 'item_id']:\n",
    "            sell_prices[col] = sell_prices[col].map(all_label_map[col])\n",
    "    \n",
    "    train = pd.melt(train, id_vars=id_columns, var_name='d', value_name='sales')\n",
    "    train = pd.merge(train, encoded_calender, how='left', on='d')\n",
    "    train = pd.merge(train, sell_prices, how='left', on=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "    # MEMO: sell_price を直近価格で過去の値を埋める。\n",
    "    train['sell_price'] = train.groupby('item_id')['sell_price'].bfill()\n",
    "#     test['sell_price'] = test.groupby('item_id')['sell_price'].bfill()\n",
    "    \n",
    "    # Save cache\n",
    "    train = train.pipe(reduce_mem_usage)\n",
    "#     test = test.pipe(reduce_mem_usage)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "    train.to_pickle(train_save_path)\n",
    "    test.to_pickle(test_save_path)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train, test = melt_and_merge(train, test, calendar, sell_prices, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58327370, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id    d  sales  wm_yr_wk  wday  month  event_name_1  event_type_1  \\\n",
       "0         0  d_1      0     11101     1      1            19             2   \n",
       "1         0  d_1      0     11101     1      1            19             2   \n",
       "2         0  d_1      0     11101     1      1            19             2   \n",
       "3         0  d_1      0     11101     1      1            19             2   \n",
       "4         0  d_1      0     11101     1      1            19             2   \n",
       "\n",
       "   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0             3             1        0        0        0    9.578125  \n",
       "1             3             1        0        0        0    3.970703  \n",
       "2             3             1        0        0        0    2.970703  \n",
       "3             3             1        0        0        0    4.339844  \n",
       "4             3             1        0        0        0    2.980469  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "# 起きたら特徴量エンジニアリングやるぞ！！！\n",
    "- とりあえず、m5-baselineのマネをするところからになりそう。\n",
    "- どんどん真似するぞ！！！\n",
    "- jazzもいくぞ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(metaclass=abc.ABCMeta):\n",
    "    prefix = \"\"\n",
    "    suffix = \"\"\n",
    "    save_dir = \"features\"\n",
    "    is_feature = True\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        Path(self.save_dir).mkdir(exist_ok=True, parents=True)\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.categoricals = pd.Series()\n",
    "        self.train_path = Path(self.save_dir) / f\"{self.name}_train.pkl\"\n",
    "        self.test_path = Path(self.save_dir) / f\"{self.name}_test.pkl\"\n",
    "        self.categoricals_path = Path(self.save_dir) / f\"{self.name}_categoricals.pkl\"\n",
    "\n",
    "    def run(self, train_df, test_df=None, log=False):\n",
    "        self.create_features(train_df, test_df)\n",
    "        prefix = self.prefix + \"_\" if self.prefix else \"\"\n",
    "        suffix = self.suffix + \"_\" if self.suffix else \"\"\n",
    "        self.train.columns = pd.Index([str(c) for c in self.train.columns])\n",
    "        self.test.columns = pd.Index([str(c) for c in self.test.columns])\n",
    "        self.train.columns = prefix + self.train.columns + suffix\n",
    "        self.test.columns = prefix + self.test.columns + suffix\n",
    "        return self\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def create_features(self, train_df, test_df):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self):\n",
    "        self.train.to_pickle(str(self.train_path))\n",
    "        self.test.to_pickle(str(self.test_path))\n",
    "        self.categoricals.to_pickle(str(self.categoricals_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Abbreviations\n",
    "\"\"\"\n",
    "class BaseFeature(Feature):\n",
    "    \n",
    "    def add_common_features(df):\n",
    "        return df\n",
    "    \n",
    "    def create_features(self, train, test):\n",
    "        # Set train, test, categoricals\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.categoricals = pd.Series(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "BaseFeature().run(raw_train, raw_test).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
